Given the following job description and collection of user experiences and data, please output a draft of which experiences/projects/skills you would write on the user's resume.

Here is the user's previous career experience: [{'company_name': 'Tech Innovators Inc.', 'start_date': 'Jan 2023', 'end_date': 'Present', 'role_title': 'Full Stack Developer', 'city': 'San Jose', 'state': 'CA', 'bullet_points': ['Designed and deployed responsive web applications using React, Node.js, and PostgreSQL.', 'Developed GraphQL APIs to streamline data fetching and reduce network overhead.', 'Improved backend performance by optimizing queries and implementing caching strategies, reducing API response time by 40%.', 'Collaborated with designers to create seamless user interfaces adhering to accessibility standards.', 'Integrated third-party payment gateways and implemented secure transaction handling.', 'Managed CI/CD pipelines using Jenkins and GitHub Actions, ensuring reliable deployments.', 'Mentored junior developers on best practices for coding and debugging.', 'Built microservices for modular application architecture, enabling scalable system growth.', 'Implemented comprehensive unit and integration tests, achieving 90% code coverage.', 'Participated in sprint planning and contributed to Agile development processes.']}, {'company_name': 'DataSys Solutions', 'start_date': 'May 2021', 'end_date': 'Dec 2022', 'role_title': 'Data Engineer', 'city': 'Boston', 'state': 'MA', 'bullet_points': ['Built ETL pipelines to process terabytes of data using Apache Airflow and Spark.', 'Streamlined data ingestion from multiple sources, improving pipeline efficiency by 50%.', 'Designed data models for efficient storage and retrieval in a Snowflake data warehouse.', 'Implemented real-time analytics dashboards using Power BI and Looker.', 'Integrated machine learning models into the pipeline to deliver predictive insights.', 'Automated data validation processes, reducing errors by 70%.', 'Collaborated with data scientists to preprocess data for training and evaluation.', 'Developed APIs to expose processed datasets to downstream applications.', 'Migrated legacy data systems to a modern cloud architecture using Azure.', 'Ensured data security and compliance with GDPR and HIPAA regulations.']}, {'company_name': 'AI Ventures', 'start_date': 'Jun 2020', 'end_date': 'Apr 2021', 'role_title': 'Machine Learning Intern', 'city': 'Chicago', 'state': 'IL', 'bullet_points': ['Developed deep learning models for image classification using PyTorch and TensorFlow.', 'Implemented transfer learning techniques to improve model accuracy by 15%.', 'Preprocessed large image datasets using OpenCV for model training.', 'Optimized model inference performance for deployment on edge devices.', 'Conducted hyperparameter tuning experiments to maximize model performance.', 'Built and deployed REST APIs to serve machine learning predictions.', 'Documented and presented results to stakeholders, leading to actionable insights.', 'Explored reinforcement learning algorithms for automated decision-making tasks.', 'Created Docker containers to package ML models for deployment.', 'Contributed to open-source AI projects, receiving community recognition.']}, {'company_name': 'Network Dynamics', 'start_date': 'Jan 2019', 'end_date': 'May 2020', 'role_title': 'Network Engineer', 'city': 'Dallas', 'state': 'TX', 'bullet_points': ['Designed and implemented secure network architectures for enterprise clients.', 'Configured routers, switches, and firewalls using Cisco IOS.', 'Monitored network traffic and identified potential security threats.', 'Optimized network performance by fine-tuning QoS settings.', 'Deployed and managed VPN solutions for remote access.', 'Automated network configuration tasks using Python scripts.', 'Diagnosed and resolved network outages, minimizing downtime.', 'Prepared technical documentation and training materials for IT teams.', 'Conducted regular network audits to ensure compliance with industry standards.', 'Collaborated with cybersecurity teams to mitigate vulnerabilities.']}, {'company_name': 'Embedded Systems Lab', 'start_date': 'Aug 2017', 'end_date': 'Dec 2018', 'role_title': 'Embedded Systems Developer', 'city': 'Pittsburgh', 'state': 'PA', 'bullet_points': ['Designed and programmed firmware for microcontrollers using C and Assembly.', 'Integrated sensors and actuators into IoT prototypes for real-time data collection.', 'Optimized system power consumption, extending device battery life by 30%.', 'Developed communication protocols over UART, SPI, and I2C interfaces.', 'Built custom PCBs using KiCad for hardware prototyping.', 'Implemented RTOS-based solutions for multitasking embedded systems.', 'Conducted hardware debugging using oscilloscopes and logic analyzers.', 'Performed stress testing and validation of embedded devices.', 'Documented hardware-software integration processes for reproducibility.', 'Collaborated with cross-disciplinary teams on project deliverables.']}]

Here is the user's projects (that may or may not be relevant): [{'project_name': 'Real-Time Financial Market Dashboard', 'skills': 'Python, Flask, React, WebSocket, MongoDB, AWS Lambda', 'description': 'Developed a real-time financial market dashboard that streams stock and cryptocurrency data using WebSocket protocols. Implemented backend services with Flask and MongoDB for data persistence, and React for a responsive frontend. Leveraged AWS Lambda to process and aggregate large volumes of financial data, ensuring sub-second latency. Integrated interactive visualizations for market trends and forecasts. Deployed the application on AWS, achieving 99.9% uptime.'}, {'project_name': 'Smart Traffic Control System', 'skills': 'Python, OpenCV, Raspberry Pi, MQTT, TensorFlow', 'description': 'Designed an AI-powered smart traffic control system capable of detecting and analyzing traffic patterns. Used Raspberry Pi and OpenCV to process real-time video feeds and TensorFlow for vehicle classification. Integrated MQTT for communication between edge devices and a centralized server. The system dynamically adjusts traffic signals, reducing congestion by up to 25% in simulations.'}, {'project_name': 'Distributed Database Replication System', 'skills': 'Java, Apache Kafka, MySQL, Docker, Kubernetes', 'description': 'Engineered a distributed database replication system using Apache Kafka to ensure high availability and consistency across geographically dispersed data centers. Utilized MySQL for data storage and Docker with Kubernetes for container orchestration. Implemented conflict resolution strategies and monitoring tools to ensure system reliability. Delivered a robust solution that reduced downtime by 70%.'}, {'project_name': 'IoT-Based Health Monitoring System', 'skills': 'C++, Arduino, Python, AWS IoT Core, MQTT', 'description': 'Developed an IoT-based health monitoring system for continuous tracking of patient vitals. Programmed Arduino devices to collect and transmit data to AWS IoT Core via MQTT. Built Python scripts to analyze and visualize patient health trends, alerting medical professionals in real time for anomalies. Successfully tested the system in pilot healthcare facilities, receiving positive feedback from stakeholders.'}, {'project_name': 'AI-Assisted Code Review Tool', 'skills': 'Python, Flask, NLP, GitHub API, Docker', 'description': 'Built an AI-assisted code review tool that leverages natural language processing to analyze code changes and generate review suggestions. Integrated with the GitHub API to automatically comment on pull requests. Used Flask for backend services and Docker for scalable deployment. The tool reduced code review time by 40% in pilot projects.'}].

 Here is the job description that you will customize the resume for: Data & Applied Scientist II
Redmond, Washington, United States

Save

Share job

Date posted
Dec 17, 2024
Job number
1791010
Work site
Up to 50% work from home
Travel
0-25 %
Role type
Individual Contributor
Profession
Research, Applied, & Data Sciences
Discipline
Applied Sciences
Employment type
Full-Time
Overview
The online advertising industry is experiencing rapid growth, delivering hundreds of millions of ad impressions daily and generating terabytes of user event data. This expansion presents incredible opportunities alongside complex technical challenges that require advanced computational intelligence. The Bing Ads Understanding team is at the forefront of this dynamic field, tackling these challenges through cutting-edge technologies, including data mining, statistical analysis, machine learning, deep learning, natural language processing, large language modeling, multi-lingual and multi-modality modeling. Our team is looking for a Data & Applied Scientist II to join us in our mission.  

Our mission centers on solving the core problem of computational advertising: selecting an optimized slate of relevant ads that maximizes a comprehensive utility function encompassing expected revenue, user experience, and advertiser return on investment.

As a world-class R&D team of passionate scientists and engineers, we are dedicated to addressing these challenges with innovative ideas and turning them into high-quality products and impactful solutions. We empower hundreds of millions of users to find what they need while enabling advertisers to reach their ideal audiences, creating a seamless marketplace experience that drives success across the board.

 

Microsoftâ€™s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

Qualifications
Required Qualifications:

Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field

o OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results) or consulting experience

OR Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 2+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)

o OR equivalent experience.

 

 

Preferred Qualifications:

Experience with Large Language Models: Demonstrated experience working with LLMs, such as GPT, BERT, or similar models, including knowledge of their strengths, limitations, and capabilities.
Understanding of NLP: In-depth knowledge of natural language processing (NLP) techniques and concepts, including tokenization, embeddings, semantic analysis, and their integration into machine learning pipelines.
Understanding and Experience with Multi-Modal Modeling: Familiarity and hands-on experience with multi-modal models such as ViT (Vision Transformer), CLIP, and LLAVA. Ability to apply these models in scenarios involving the integration of text and visual data for tasks such as cross-modal understanding, retrieval, relevance and ranking.
Proven ability to work independently in a team to deliver innovative solutions solving challenging business/technical problems from high level vision and architecture, down to quality design and implementation. Self-motivated and self-directed and be able to work constructively with a wide variety of people, team and changing business priorities
Understanding of state-of-the-art machine learning and deep learning technologies. In particular, hands-on experiences with deep learning models (DNN, CNN, RNN, Attention, Transformer) and frameworks (TensorFlow, PyTorch, Keras, etc.)
 

 

Applied Sciences IC3 - The typical base pay range for this role across the U.S. is USD $98,300 - $193,200 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $127,200 - $208,800 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until January 7, 2025


 


 

Responsibilities
Response and Resolution:

Leverages understanding of data science and business to examine a project and consider factors that can influence final outcomes within a technical area. Evaluates project plan for resources, risks, contingencies, requirements, assumptions, and constraints. Documents key business objectives. Effectively communicates business goals in analytical and technical terms. Consistently shares insights with stakeholders.
Build and maintain production-level machine learning models to assess and predict the relevance between ads and diverse user contexts, such as search queries or conversational interactions. Employ cutting-edge techniques, including large language models (LLMs) and state-of-the-art innovations from academia and industry, to enhance relevance modeling and drive impactful outcomes. Utilize Python, PyTorch and open-source libraries to train and fine-tune large language models. Apply advanced techniques like transfer learning, domain adaptation, and prompt engineering to tailor pre-trained LLMs to specific advertising scenarios. Build efficient training pipelines, inference pipelines for offline and online serving on production environments.
 

Readiness:

Understands where to acquire data necessary for successful completion of the project plan. Utilizes querying, visualization, and reporting techniques to describe acquired data, including format, quantity, identities, and other surface properties. Explores data for key attributes and contributes to the development of data quality report describing results of the task, initial findings, and impact on the project. Collaborates with others to perform data-science experiments using established methodologies, statistics, optimization, and probability theory for general purpose software and statistical packages. Assesses different tools and techniques and selects the appropriate one. Serves as an effective partner in data preparation efforts to Solution Architects, Consultants, and Data Engineers. Adheres to Microsoft's privacy policy related to collecting and preparing data. Identifies data integrity problems.
Derive meaningful insights and generate hypotheses from massive datasets using a variety of advanced techniques such as machine learning, feature engineering, statistical modeling, and data mining. Leverage methods like regression, classification, natural language processing (NLP), optimization, and p-value analysis to solve complex problems effectively.
 

Product/Process Improvement:

Leverages knowledge of machine learning solutions (e.g., classification, regression, clustering, forecasting, natural language processing [NLP], image recognition) and individual algorithms (e.g., linear and logistic regression, k-means, gradient boosting, autoregressive integrated moving average [ARIMA], recurrent neutral networks [RNN], long short-term memory [LSTM] networks) to identify the best approach to complete objectives. Understands modeling techniques (e.g., dimensionality reduction, cross-validation, regularization, encoding, assembling, activation functions) and selects the correct approach to prepare data, train and optimize the model, and evaluate the output for statistical and business significance. Understands the risks of data leakage, the bias/variance tradeoff, methodological limitations, etc. Writes all necessary scripts in the appropriate language: T-SQL, U-SQL, KQL, Python, R, etc. Constructs hypotheses, designs controlled experiments, analyzes results using statistical tests, and communicates findings to business stakeholders. Effectively communicates with diverse audiences on data-quality issues and initiatives. Understands operational considerations of model deployment, such as performance, scalability, monitoring, maintenance, integration into engineering production system, stability. Develops operational models that run at scale through partnership with data engineering teams.
 

 

Business Integration:

Leverages understanding of data science and business to examine projects through a customer-oriented focus. Manages customer expectations regarding project/product progress and timeline. Takes responsibility to enhance customer excellence. Assists and learns from senior team members interpret results, develops insights, and communicates results to customers. Possesses basic understanding about model accuracy dependency on data quality and able to articulate it in customer discussions.
Manage and manipulate petabyte-scale datasets using a combination of open-source and proprietary tools. Proficiency in programming languages like Python, R, C#, C++, Java, and SQL is highly valued to implement scalable data workflows and pipelines.
 

Other Â· Embody our culture and values


